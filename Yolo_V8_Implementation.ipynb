{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Yolo V8 Implementation on costume data.\n",
        "\n",
        "#### Modes\n",
        "train, val, predict\n",
        "#### Tasks\n",
        "detect, segment, classify\n",
        "#### Data:\n",
        "format can be anything jpg, yaml, datafolder, dataset name"
      ],
      "metadata": {
        "id": "KZ7WRH98cKC2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up library"
      ],
      "metadata": {
        "id": "zw8EpkmFd3P1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install ultralytics\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pu_9_qAMbArx",
        "outputId": "be829ec0-86ad-4550-be16-93c223b9f9bd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.192 🚀 Python-3.10.12 torch-2.0.1+cu118 CPU (Intel Xeon 2.20GHz)\n",
            "Setup complete ✅ (2 CPUs, 12.7 GB RAM, 26.4/107.7 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOxVOWJBYtZF",
        "outputId": "f304812a-5c15-4949-bede-6129f3c98a30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.0.192 🚀 Python-3.10.12 torch-2.0.1+cu118 CPU (Intel Xeon 2.20GHz)\n",
            "YOLOv8n summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n",
            "\n",
            "image 1/1 /content/image1.jpg: 384x640 7 dogs, 241.0ms\n",
            "Speed: 17.0ms preprocess, 241.0ms inference, 31.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/predict\n"
          ]
        }
      ],
      "source": [
        "# detection\n",
        "!yolo task = detect mode=predict model = yolov8n.pt source = '/content/image1.jpg'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# segment\n",
        "!yolo task = segment mode=predict model = yolov8n-seg.pt source = '/content/image1.jpg'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ibkJiVMbU9x",
        "outputId": "f9b3965c-c84a-49e8-ca54-17ee62dafd20"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n-seg.pt to 'yolov8n-seg.pt'...\n",
            "100% 6.73M/6.73M [00:00<00:00, 42.7MB/s]\n",
            "Ultralytics YOLOv8.0.192 🚀 Python-3.10.12 torch-2.0.1+cu118 CPU (Intel Xeon 2.20GHz)\n",
            "YOLOv8n-seg summary (fused): 195 layers, 3404320 parameters, 0 gradients, 12.6 GFLOPs\n",
            "\n",
            "image 1/1 /content/image1.jpg: 384x640 7 dogs, 1 teddy bear, 289.6ms\n",
            "Speed: 5.6ms preprocess, 289.6ms inference, 27.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/segment/predict\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/predict\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "model = YOLO('yolov8n-seg.pt')\n",
        "model.predict(source = '/content/image1.jpg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKmUZPNBgJPO",
        "outputId": "3ec87537-ac1d-487c-c8e5-b87d6995f912"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "image 1/1 /content/image1.jpg: 640x640 1 dog, 254.5ms\n",
            "Speed: 7.1ms preprocess, 254.5ms inference, 4.1ms postprocess per image at shape (1, 3, 640, 640)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: ultralytics.engine.results.Masks object\n",
              " names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
              " orig_img: array([[[123, 188, 166],\n",
              "         [123, 188, 166],\n",
              "         [123, 188, 166],\n",
              "         ...,\n",
              "         [115, 182, 161],\n",
              "         [115, 182, 161],\n",
              "         [115, 182, 161]],\n",
              " \n",
              "        [[123, 188, 166],\n",
              "         [123, 188, 166],\n",
              "         [123, 188, 166],\n",
              "         ...,\n",
              "         [116, 183, 162],\n",
              "         [116, 183, 162],\n",
              "         [116, 183, 162]],\n",
              " \n",
              "        [[123, 188, 166],\n",
              "         [123, 188, 166],\n",
              "         [123, 188, 166],\n",
              "         ...,\n",
              "         [116, 183, 162],\n",
              "         [116, 183, 162],\n",
              "         [116, 183, 162]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[ 54, 122,  99],\n",
              "         [ 54, 122,  99],\n",
              "         [ 54, 122,  99],\n",
              "         ...,\n",
              "         [ 72, 126, 121],\n",
              "         [ 72, 126, 121],\n",
              "         [ 72, 126, 121]],\n",
              " \n",
              "        [[ 54, 122,  99],\n",
              "         [ 54, 122,  99],\n",
              "         [ 54, 122,  99],\n",
              "         ...,\n",
              "         [ 72, 126, 121],\n",
              "         [ 72, 126, 121],\n",
              "         [ 72, 126, 121]],\n",
              " \n",
              "        [[ 52, 122,  99],\n",
              "         [ 52, 122,  99],\n",
              "         [ 51, 121,  98],\n",
              "         ...,\n",
              "         [ 75, 127, 120],\n",
              "         [ 75, 127, 120],\n",
              "         [ 74, 126, 119]]], dtype=uint8)\n",
              " orig_shape: (1197, 1200)\n",
              " path: '/content/image1.jpg'\n",
              " probs: None\n",
              " save_dir: None\n",
              " speed: {'preprocess': 7.053136825561523, 'inference': 254.46081161499023, 'postprocess': 4.11534309387207}]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## classify\n",
        "!yolo task = classify mode = predict model = yolov8n-cls.pt source = '/content/image1.jpg'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ohyjitcggJe",
        "outputId": "84dd5e4f-1944-476a-a9b8-736f28b1c02a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n-cls.pt to 'yolov8n-cls.pt'...\n",
            "100% 5.28M/5.28M [00:00<00:00, 210MB/s]\n",
            "Ultralytics YOLOv8.0.191 🚀 Python-3.10.12 torch-2.0.1+cu118 CPU (AMD EPYC 7B12)\n",
            "YOLOv8n-cls summary (fused): 73 layers, 2715880 parameters, 0 gradients, 4.3 GFLOPs\n",
            "\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n",
            "100% 755k/755k [00:00<00:00, 74.2MB/s]\n",
            "image 1/1 /content/image1.jpg: 224x224 golden_retriever 0.22, Bedlington_terrier 0.12, Tibetan_terrier 0.08, miniature_poodle 0.07, standard_poodle 0.06, 35.9ms\n",
            "Speed: 8.2ms preprocess, 35.9ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "Results saved to \u001b[1mruns/classify/predict\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/predict\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training on costume dataset"
      ],
      "metadata": {
        "id": "B0qxBiLvhGFr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download COCO val\n",
        "import torch\n",
        "torch.hub.download_url_to_file('https://ultralytics.com/assets/coco2017val.zip', 'tmp.zip')  # download (780M - 5000 images)\n",
        "!unzip -q tmp.zip -d datasets && rm tmp.zip  # unzip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQgB4-y7ltJB",
        "outputId": "79332025-4e27-4344-d74c-813877119c91"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 780M/780M [00:07<00:00, 108MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "model = YOLO()\n",
        "# model = YOLO('yolov8n.pt')## load the pretrain\n",
        "## if you dont want to use pretrain use this at it is.. dont use above command\n",
        "model.train(data = 'coco8.yaml', epochs = 50)"
      ],
      "metadata": {
        "id": "43zEQeiEeaX_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cef2a17e-1e29-4141-c328-8b3903c42506"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.192 🚀 Python-3.10.12 torch-2.0.1+cu118 CPU (Intel Xeon 2.20GHz)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=coco8.yaml, epochs=50, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "\n",
            "Dataset 'coco8.yaml' images not found ⚠️, missing path '/content/datasets/coco8/images/val'\n",
            "Downloading https://ultralytics.com/assets/coco8.zip to '/content/datasets/coco8.zip'...\n",
            "100%|██████████| 433k/433k [00:00<00:00, 10.0MB/s]\n",
            "Unzipping /content/datasets/coco8.zip to /content/datasets/coco8...: 100%|██████████| 25/25 [00:00<00:00, 2683.63file/s]\n",
            "Dataset download success ✅ (0.5s), saved to \u001b[1m/content/datasets\u001b[0m\n",
            "\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n",
            "100%|██████████| 755k/755k [00:00<00:00, 15.4MB/s]\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
            "Model summary: 225 layers, 3157200 parameters, 3157184 gradients, 8.9 GFLOPs\n",
            "\n",
            "Transferred 355/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/coco8/labels/train... 4 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4/4 [00:00<00:00, 262.08it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/coco8/labels/train.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco8/labels/val... 4 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4/4 [00:00<00:00, 19328.59it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/coco8/labels/val.cache\n",
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       1/50         0G      1.408      3.273      1.584         37        640: 100%|██████████| 1/1 [00:03<00:00,  3.81s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.76s/it]\n",
            "                   all          4         17      0.901      0.523      0.721      0.511\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       2/50         0G      1.255      3.035      1.529         39        640: 100%|██████████| 1/1 [00:03<00:00,  3.73s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.46s/it]\n",
            "                   all          4         17      0.906      0.532      0.743      0.518\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       3/50         0G      1.291      3.945      1.649         18        640: 100%|██████████| 1/1 [00:03<00:00,  3.20s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.35s/it]\n",
            "                   all          4         17      0.908      0.537      0.752      0.514\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       4/50         0G      1.206      3.722      1.542         43        640: 100%|██████████| 1/1 [00:04<00:00,  4.45s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.20s/it]\n",
            "                   all          4         17      0.911      0.542      0.779      0.527\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       5/50         0G     0.9486      2.462      1.358         18        640: 100%|██████████| 1/1 [00:03<00:00,  3.10s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.18s/it]\n",
            "                   all          4         17      0.913      0.545      0.777       0.55\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       6/50         0G      1.169       3.36      1.495         41        640: 100%|██████████| 1/1 [00:03<00:00,  3.12s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.81s/it]\n",
            "                   all          4         17      0.917       0.55      0.753      0.545\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       7/50         0G      1.287      2.609      1.557         19        640: 100%|██████████| 1/1 [00:03<00:00,  3.36s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.20s/it]\n",
            "                   all          4         17       0.92       0.55       0.75      0.538\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       8/50         0G      1.241      3.102      1.586         23        640: 100%|██████████| 1/1 [00:03<00:00,  3.07s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.18s/it]\n",
            "                   all          4         17      0.922       0.55      0.751      0.533\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       9/50         0G      1.046      2.837      1.405         36        640: 100%|██████████| 1/1 [00:04<00:00,  4.62s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.20s/it]\n",
            "                   all          4         17      0.933       0.55      0.834      0.561\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      10/50         0G      1.188      3.032      1.649         16        640: 100%|██████████| 1/1 [00:03<00:00,  3.12s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.18s/it]\n",
            "                   all          4         17       0.94       0.55      0.836      0.552\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      11/50         0G     0.8631      3.001      1.356         13        640: 100%|██████████| 1/1 [00:03<00:00,  3.09s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.47s/it]\n",
            "                   all          4         17      0.946       0.55      0.836      0.568\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      12/50         0G        1.1      2.211      1.456         36        640: 100%|██████████| 1/1 [00:03<00:00,  3.65s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.19s/it]\n",
            "                   all          4         17      0.916       0.55      0.839      0.553\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      13/50         0G      1.053      2.659       1.42         31        640: 100%|██████████| 1/1 [00:03<00:00,  3.17s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.18s/it]\n",
            "                   all          4         17      0.884       0.55       0.84      0.555\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      14/50         0G       1.04       2.19       1.26         33        640: 100%|██████████| 1/1 [00:04<00:00,  4.23s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.40s/it]\n",
            "                   all          4         17      0.875       0.55      0.847      0.554\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      15/50         0G      1.188      2.063      1.473         11        640: 100%|██████████| 1/1 [00:03<00:00,  3.14s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
            "                   all          4         17      0.862       0.55      0.743      0.542\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      16/50         0G      1.255      2.483      1.573         31        640: 100%|██████████| 1/1 [00:03<00:00,  3.29s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.68s/it]\n",
            "                   all          4         17      0.833       0.55      0.743      0.542\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      17/50         0G      1.052       2.63      1.409         38        640: 100%|██████████| 1/1 [00:05<00:00,  5.14s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.19s/it]\n",
            "                   all          4         17      0.796      0.554      0.742      0.526\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      18/50         0G     0.9556      3.482      1.525         19        640: 100%|██████████| 1/1 [00:03<00:00,  3.11s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.18s/it]\n",
            "                   all          4         17      0.796      0.554      0.742      0.526\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      19/50         0G      1.063      2.486      1.436         24        640: 100%|██████████| 1/1 [00:04<00:00,  4.24s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.33s/it]\n",
            "                   all          4         17      0.788      0.563       0.66      0.486\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      20/50         0G     0.8342      1.624      1.275         28        640: 100%|██████████| 1/1 [00:03<00:00,  3.15s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.18s/it]\n",
            "                   all          4         17      0.788      0.563       0.66      0.486\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      21/50         0G     0.7968      2.338      1.288         23        640: 100%|██████████| 1/1 [00:03<00:00,  3.15s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.21s/it]\n",
            "                   all          4         17      0.757      0.582      0.657       0.48\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      22/50         0G     0.9443      1.946       1.26         32        640: 100%|██████████| 1/1 [00:04<00:00,  4.46s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.56s/it]\n",
            "                   all          4         17      0.757      0.582      0.657       0.48\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      23/50         0G      1.107      2.165      1.378         41        640: 100%|██████████| 1/1 [00:05<00:00,  5.19s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.29s/it]\n",
            "                   all          4         17      0.782      0.578       0.63      0.473\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      24/50         0G      1.228      2.629      1.465         29        640: 100%|██████████| 1/1 [00:03<00:00,  4.00s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.19s/it]\n",
            "                   all          4         17      0.782      0.578       0.63      0.473\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      25/50         0G      0.851       1.59      1.239         29        640: 100%|██████████| 1/1 [00:03<00:00,  3.18s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.21s/it]\n",
            "                   all          4         17      0.769      0.583       0.66      0.464\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      26/50         0G     0.8816      1.558      1.194         32        640: 100%|██████████| 1/1 [00:03<00:00,  3.87s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
            "                   all          4         17      0.769      0.583       0.66      0.464\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      27/50         0G     0.8598      1.858       1.28         32        640: 100%|██████████| 1/1 [00:03<00:00,  3.18s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.21s/it]\n",
            "                   all          4         17      0.936      0.383      0.631      0.448\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      28/50         0G     0.8952      1.492      1.376         16        640: 100%|██████████| 1/1 [00:03<00:00,  3.12s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.19s/it]\n",
            "                   all          4         17      0.936      0.383      0.631      0.448\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      29/50         0G      1.211      2.237      1.671         15        640: 100%|██████████| 1/1 [00:04<00:00,  4.33s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.19s/it]\n",
            "                   all          4         17      0.938      0.383      0.599      0.452\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      30/50         0G     0.7039      1.491      1.111         23        640: 100%|██████████| 1/1 [00:03<00:00,  3.14s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.18s/it]\n",
            "                   all          4         17      0.938      0.383      0.599      0.452\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      31/50         0G     0.7538      1.337      1.101         31        640: 100%|██████████| 1/1 [00:03<00:00,  3.47s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.83s/it]\n",
            "                   all          4         17      0.934      0.383      0.598      0.451\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      32/50         0G      0.764      1.139      1.306         13        640: 100%|██████████| 1/1 [00:03<00:00,  3.10s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.18s/it]\n",
            "                   all          4         17      0.934      0.383      0.598      0.451\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      33/50         0G      0.955      1.383      1.246         43        640: 100%|██████████| 1/1 [00:03<00:00,  3.22s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.18s/it]\n",
            "                   all          4         17      0.938      0.383        0.6      0.434\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      34/50         0G     0.9685      1.774      1.351         36        640: 100%|██████████| 1/1 [00:04<00:00,  4.39s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.18s/it]\n",
            "                   all          4         17      0.938      0.383        0.6      0.434\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      35/50         0G     0.8831      1.507      1.166         33        640: 100%|██████████| 1/1 [00:03<00:00,  3.22s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.18s/it]\n",
            "                   all          4         17      0.937      0.383        0.6      0.433\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      36/50         0G     0.9907      1.913      1.408         17        640: 100%|██████████| 1/1 [00:03<00:00,  3.10s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.79s/it]\n",
            "                   all          4         17      0.937      0.383        0.6      0.433\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      37/50         0G      1.078      1.782      1.271         40        640: 100%|██████████| 1/1 [00:03<00:00,  3.57s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.18s/it]\n",
            "                   all          4         17      0.777      0.383      0.599       0.43\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      38/50         0G      1.025      1.434      1.302         35        640: 100%|██████████| 1/1 [00:03<00:00,  3.14s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.20s/it]\n",
            "                   all          4         17      0.777      0.383      0.599       0.43\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      39/50         0G     0.8928      1.598      1.302         30        640: 100%|██████████| 1/1 [00:04<00:00,  4.49s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.18s/it]\n",
            "                   all          4         17      0.777      0.383      0.577      0.427\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      40/50         0G     0.8596      1.004      1.332         19        640: 100%|██████████| 1/1 [00:03<00:00,  3.13s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.18s/it]\n",
            "                   all          4         17      0.777      0.383      0.577      0.427\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      41/50         0G     0.7167     0.9847      1.061         13        640: 100%|██████████| 1/1 [00:03<00:00,  3.16s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.74s/it]\n",
            "                   all          4         17      0.943      0.383      0.577      0.428\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      42/50         0G     0.8788     0.9005      1.206         13        640: 100%|██████████| 1/1 [00:03<00:00,  3.55s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.29s/it]\n",
            "                   all          4         17      0.943      0.383      0.577      0.428\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      43/50         0G     0.7651      1.097      1.146         13        640: 100%|██████████| 1/1 [00:03<00:00,  3.15s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.28s/it]\n",
            "                   all          4         17      0.942      0.383      0.577      0.428\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      44/50         0G     0.6454     0.8375      1.022         13        640: 100%|██████████| 1/1 [00:04<00:00,  4.22s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.38s/it]\n",
            "                   all          4         17      0.942      0.383      0.577      0.428\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      45/50         0G     0.6288      1.034      1.048         13        640: 100%|██████████| 1/1 [00:03<00:00,  3.13s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.21s/it]\n",
            "                   all          4         17      0.938      0.383      0.576      0.427\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      46/50         0G     0.6777     0.9446      1.177         13        640: 100%|██████████| 1/1 [00:03<00:00,  3.11s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.22s/it]\n",
            "                   all          4         17      0.938      0.383      0.576      0.427\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      47/50         0G     0.6277     0.7148     0.9533         13        640: 100%|██████████| 1/1 [00:04<00:00,  4.01s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.21s/it]\n",
            "                   all          4         17      0.934      0.383      0.576      0.426\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      48/50         0G     0.6587      1.226      1.173         13        640: 100%|██████████| 1/1 [00:03<00:00,  3.11s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.18s/it]\n",
            "                   all          4         17      0.934      0.383      0.576      0.426\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      49/50         0G     0.6095     0.8925      1.026         13        640: 100%|██████████| 1/1 [00:03<00:00,  3.66s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.78s/it]\n",
            "                   all          4         17      0.933      0.383      0.588      0.428\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      50/50         0G     0.6583      1.053      1.147         13        640: 100%|██████████| 1/1 [00:03<00:00,  3.10s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.19s/it]\n",
            "                   all          4         17      0.933      0.383      0.588      0.428\n",
            "\n",
            "50 epochs completed in 0.074 hours.\n",
            "Optimizer stripped from runs/detect/train/weights/last.pt, 6.5MB\n",
            "Optimizer stripped from runs/detect/train/weights/best.pt, 6.5MB\n",
            "\n",
            "Validating runs/detect/train/weights/best.pt...\n",
            "Ultralytics YOLOv8.0.192 🚀 Python-3.10.12 torch-2.0.1+cu118 CPU (Intel Xeon 2.20GHz)\n",
            "Model summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.02s/it]\n",
            "                   all          4         17      0.946       0.55      0.836      0.552\n",
            "                person          4         10      0.997        0.3      0.476      0.227\n",
            "                   dog          4          1          1          0      0.995      0.443\n",
            "                 horse          4          2      0.969          1      0.995      0.698\n",
            "              elephant          4          2          1          0      0.559     0.0559\n",
            "              umbrella          4          1      0.778          1      0.995      0.995\n",
            "          potted plant          4          1      0.933          1      0.995      0.895\n",
            "Speed: 2.3ms preprocess, 240.0ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
              "\n",
              "ap_class_index: array([ 0, 16, 17, 20, 25, 58])\n",
              "box: ultralytics.utils.metrics.Metric object\n",
              "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7ab2f8340130>\n",
              "fitness: 0.5808227030791256\n",
              "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
              "maps: array([     0.2272,      0.5525,      0.5525,      0.5525,      0.5525,      0.5525,      0.5525,      0.5525,      0.5525,      0.5525,      0.5525,      0.5525,      0.5525,      0.5525,      0.5525,      0.5525,     0.44323,     0.69818,      0.5525,      0.5525,    0.055875,      0.5525,      0.5525,      0.5525,\n",
              "            0.5525,       0.995,      0.5525,      0.5525,      0.5525,      0.5525,      0.5525,      0.5525,      0.5525,      0.5525,      0.5525,      0.5525,      0.5525,      0.5525,      0.5525,      0.5525,      0.5525,      0.5525,      0.5525,      0.5525,      0.5525,      0.5525,      0.5525,      0.5525,\n",
              "            0.5525,      0.5525,      0.5525,      0.5525,      0.5525,      0.5525,      0.5525,      0.5525,      0.5525,      0.5525,      0.8955,      0.5525,      0.5525,      0.5525,      0.5525,      0.5525,      0.5525,      0.5525,      0.5525,      0.5525,      0.5525,      0.5525,      0.5525,      0.5525,\n",
              "            0.5525,      0.5525,      0.5525,      0.5525,      0.5525,      0.5525,      0.5525,      0.5525])\n",
              "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
              "plot: True\n",
              "results_dict: {'metrics/precision(B)': 0.9461922151955218, 'metrics/recall(B)': 0.5499999999999999, 'metrics/mAP50(B)': 0.8357463562054525, 'metrics/mAP50-95(B)': 0.552497852731756, 'fitness': 0.5808227030791256}\n",
              "save_dir: PosixPath('runs/detect/train')\n",
              "speed: {'preprocess': 2.3467540740966797, 'inference': 239.95274305343628, 'loss': 0.0010728836059570312, 'postprocess': 1.958906650543213}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Validation on costume dataset"
      ],
      "metadata": {
        "id": "Q4qwFl6ohB0R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "!yolo task = detect mode = val model = '/content/runs/detect/train/weights/best.pt' data = coco8.yaml"
      ],
      "metadata": {
        "id": "aRYIgbGufHph",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6319d472-e13c-496a-d2cf-c32bafb678b2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.0.192 🚀 Python-3.10.12 torch-2.0.1+cu118 CPU (Intel Xeon 2.20GHz)\n",
            "Model summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco8/labels/val.cache... 4 images, 0 backgrounds, 0 corrupt: 100% 4/4 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:01<00:00,  1.89s/it]\n",
            "                   all          4         17      0.946       0.55      0.836      0.552\n",
            "                person          4         10      0.997        0.3      0.476      0.227\n",
            "                   dog          4          1          1          0      0.995      0.443\n",
            "                 horse          4          2      0.969          1      0.995      0.698\n",
            "              elephant          4          2          1          0      0.559     0.0559\n",
            "              umbrella          4          1      0.778          1      0.995      0.995\n",
            "          potted plant          4          1      0.933          1      0.995      0.895\n",
            "Speed: 14.0ms preprocess, 439.8ms inference, 0.0ms loss, 4.2ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/val\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lx0yAqkihJFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing on costume dataset"
      ],
      "metadata": {
        "id": "ZST9SfrchJyO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo task = detect mode = predict model = '/content/runs/detect/train/weights/best.pt' conf = 0.25 source = 'https://ultralytics.com/images/bus.jpg'"
      ],
      "metadata": {
        "id": "dgFBi58Pfu3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c92d9b58-ef7c-4f93-9c5b-6b675c5aaf26"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.0.192 🚀 Python-3.10.12 torch-2.0.1+cu118 CPU (Intel Xeon 2.20GHz)\n",
            "Model summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n",
            "\n",
            "Downloading https://ultralytics.com/images/bus.jpg to 'bus.jpg'...\n",
            "100% 476k/476k [00:00<00:00, 9.16MB/s]\n",
            "image 1/1 /content/bus.jpg: 640x480 4 persons, 2 buss, 1 stop sign, 243.5ms\n",
            "Speed: 6.5ms preprocess, 243.5ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Results saved to \u001b[1mruns/detect/predict2\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/predict\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VcbOBxiBnht5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}